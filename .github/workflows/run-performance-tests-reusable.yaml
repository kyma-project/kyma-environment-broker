name: Run performance tests (reusable)

on:
  workflow_call:
    inputs:
      release:
        description: 'Determines if the workflow is called from release'
        default: 'true'
        type: string
      version:
        description: 'Release version'
        default: '0.0.0.0'
        type: string
      instances-number:
        description: number of instances to be provisioned
        default: '100'
        type: string
      updates-number:
        description: number of updates on a single instance
        default: '300'
        type: string
      kim-delay-seconds:
        description: time to wait before transitioning the runtime CR to the Ready state
        default: '0'
        type: string
      provisioning-max-step-processing-time:
        description: max time to process a step in provisioning queue
        default: '30s'
        type: string
      provisioning-workers-amount:
        description: amount of workers in provisioning queue
        default: '200'
        type: string
      update-max-step-processing-time:
        description: max time to process a step in update queue
        default: '30s'
        type: string
      update-workers-amount:
        description: amount of workers in update queue
        default: '25'
        type: string
      deprovisioning-max-step-processing-time:
        description: max time to process a step in deprovisioning queue
        default: '30s'
        type: string
      deprovisioning-workers-amount:
        description: amount of workers in deprovisioning queue
        default: '25'
        type: string
      baseline-monitoring-minutes:
        description: 'Duration of baseline monitoring before tests (minutes)'
        default: '0'
        type: string
      post-test-monitoring-minutes:
        description: 'Duration of post-test monitoring after tests (minutes)'
        default: '0'
        type: string
      test-duration-minutes:
        description: 'Duration for each test to run (minutes, 0 means run until completion)'
        default: '0'
        type: string
      memory-growth-threshold-percent:
        description: 'Allowed memory growth percent (over baseline)'
        default: '70'
        type: string
      goroutine-increase-threshold:
        description: 'Allowed increase in goroutines (absolute)'
        default: '50'
        type: string
      fd-increase-threshold:
        description: 'Allowed increase in open file descriptors (absolute)'
        default: '10'
        type: string
      db-conn-increase-threshold:
        description: 'Allowed increase in DB connections (absolute)'
        default: '5'
        type: string

      # (durations are already defined earlier in inputs)

jobs:
  prepare-tests:
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.get-version.outputs.k3s_version }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - id: get-version
        name: Get K3s version
        run: |
          VERSION=($(./scripts/testing/get-latest-k3s-releases.sh 1 | jq -r))
          echo "k3s_version=${VERSION}" >> "${GITHUB_OUTPUT}"
      - name: Wait for images to be ready
        uses: wechuli/allcheckspassed@f423b273f5fdf73582e41f8f6f0f204d69c27379
        if: ${{ inputs.release == 'false' }}
        with:
          delay: '1'
          retries: '15'
          polling_interval: '1'
          checks_include: 'kyma-environment-broker-image / Build image, environments-cleanup-image / Build image, deprovision-retrigger-image / Build image, expirator-image / Build image, runtime-reconciler-image / Build image, subaccount-cleanup-image / Build image, subaccount-sync-image / Build image, globalaccounts-image / Build image, schema-migrator-image / Build image, service-binding-cleanup-image / Build image'
          verbose: true

  run-concurrent-provisioning-test:
    runs-on: ubuntu-latest
    needs: prepare-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Prepare K3s cluster and docker registry
        run: "./scripts/testing/k3s-setup.sh ${{ needs.prepare-tests.outputs.version }} --wait"
        
      - name: Prepare values.yaml
        run: |
          yq e ".provisioning.maxStepProcessingTime = \"${{ inputs.provisioning-max-step-processing-time }}\"" -i resources/keb/values.yaml
          yq e ".provisioning.workersAmount = ${{ inputs.provisioning-workers-amount }}" -i resources/keb/values.yaml

      - name: Install KEB chart
        run: |
          if [ "${{ inputs.release }}" == "true" ]; then
            make install VERSION="1.25.18"
          else
            make install VERSION="1.25.18"
          fi

      - name: Populate database
        run: |
          DB_NAME=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-db-name}" | base64 -d)
          DB_USER=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-username}" | base64 -d)
          DB_PASS=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-password}" | base64 -d)
          
          kubectl port-forward -n kcp-system deployment/postgres 5432:5432 &
          PORT_FORWARD_PID=$!
          echo $PORT_FORWARD_PID
          sleep 5
          
          PGPASSWORD=$DB_PASS psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -f resources/installation/migrations/populate_performance_tests_database.up.sql
          
          kill $PORT_FORWARD_PID
          
      - name: Start metrics collector
        run: |
          nohup bash scripts/monitor_metrics.sh > /dev/null 2>&1 &
          echo $! > /tmp/metrics_pid

      - name: Baseline monitoring period
        if: ${{ inputs.baseline-monitoring-minutes > 0 }}
        run: |
          echo "Collecting baseline metrics for ${{ inputs.baseline-monitoring-minutes }} minutes..."
          sleep $((${{ inputs.baseline-monitoring-minutes }} * 60))
          echo "Baseline monitoring completed"

      - name: Provision instances
        run: |
          START_TIME=$(date +%s)
          TEST_DURATION_SECONDS=$((${{ inputs.test-duration-minutes }} * 60))
          
          if [ "$TEST_DURATION_SECONDS" -gt 0 ]; then
            echo "Running provisioning test for ${{ inputs.test-duration-minutes }} minutes..."
            
            while true; do
              ELAPSED=$(($(date +%s) - START_TIME))
              if [ $ELAPSED -ge $TEST_DURATION_SECONDS ]; then
                echo "Test duration reached, stopping provisioning requests"
                break
              fi
              
              for i in $(seq 1 ${{ inputs.instances-number }}); do
                uid=$(uuidgen)
                curl --request PUT \
                  --url http://localhost:30080/oauth/v2/service_instances/$uid \
                  --header "Content-Type: application/json" \
                  --header "X-Broker-API-Version: 2.16" \
                  --data "{\"service_id\":\"47c9dcbf-ff30-448e-ab36-d3bad66ba281\",\"plan_id\":\"4deee563-e5ec-4731-b9b1-53b42d855f0c\",\"context\":{\"globalaccount_id\":\"2f5011af-2fd3-44ba-ac60-eeb1148c2995\",\"subaccount_id\":\"8b9a0db4-9aef-4da2-a856-61a4420b66fd\",\"user_id\":\"user@email.com\"},\"parameters\":{\"name\":\"azure-cluster\",\"region\":\"northeurope\"}}"
              done
              
              echo "Provisioned batch of ${{ inputs.instances-number }} instances, elapsed: ${ELAPSED}s"
              sleep 10
            done
          else
            echo "Running provisioning test once..."
            for i in $(seq 1 ${{ inputs.instances-number }}); do
              uid=$(uuidgen)
              curl --request PUT \
                --url http://localhost:30080/oauth/v2/service_instances/$uid \
                --header "Content-Type: application/json" \
                --header "X-Broker-API-Version: 2.16" \
                --data "{\"service_id\":\"47c9dcbf-ff30-448e-ab36-d3bad66ba281\",\"plan_id\":\"4deee563-e5ec-4731-b9b1-53b42d855f0c\",\"context\":{\"globalaccount_id\":\"2f5011af-2fd3-44ba-ac60-eeb1148c2995\",\"subaccount_id\":\"8b9a0db4-9aef-4da2-a856-61a4420b66fd\",\"user_id\":\"user@email.com\"},\"parameters\":{\"name\":\"azure-cluster\",\"region\":\"northeurope\"}}"
            done
          fi
          
          TOTAL_COUNT=$(curl --request GET \
            --url http://localhost:30080/runtimes?plan=azure \
            --header 'Content-Type: application/json' \
            --header 'X-Broker-API-Version: 2.16' | jq .totalCount)

          echo "Total instances created: $TOTAL_COUNT"
      
      - name: Simulate KIM
        timeout-minutes: 60
        env:
          KIM_DELAY_SECONDS: ${{ inputs.kim-delay-seconds }}
        run: scripts/simulate_kim.sh
        
      - name: Post-test monitoring period
        if: ${{ inputs.post-test-monitoring-minutes > 0 }}
        run: |
          echo "Post-test monitoring for ${{ inputs.post-test-monitoring-minutes }} minutes..."
          sleep $((${{ inputs.post-test-monitoring-minutes }} * 60))
          echo "Post-test monitoring completed"

      - name: Fetch metrics
        run: |          
          METRICS=$(curl -s http://localhost:30080/metrics)
          
          SUCCEEDED_TOTAL=$(echo "$METRICS" | grep 'kcp_keb_v2_operations_provisioning_succeeded_total{plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c"}' | awk '{print $2}')
          SUCCEEDED_TOTAL=${SUCCEEDED_TOTAL:-0}
          FAILED_TOTAL=$(echo "$METRICS" | grep 'kcp_keb_v2_operations_provisioning_failed_total{plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c"}' | awk '{print $2}')
          FAILED_TOTAL=${FAILED_TOTAL:-0}
          TOTAL=$(echo "$SUCCEEDED_TOTAL + $FAILED_TOTAL" | bc)
          if [ "$TOTAL" -eq 0 ]; then
            SUCCESS_RATE=0
          else
            SUCCESS_RATE=$(awk "BEGIN {printf \"%.2f\", ($SUCCEEDED_TOTAL / $TOTAL) * 100}")
          fi
          echo "Success rate of provisioning requests: $SUCCESS_RATE%" >> $GITHUB_STEP_SUMMARY
          
          PROVISIONING_DURATION=$(echo "$METRICS" | grep 'kcp_keb_v2_provisioning_duration_minutes_sum{plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c"}' | awk '{print $2}')
          PROVISIONING_DURATION=${PROVISIONING_DURATION:-0}
          PROVISIONING_COUNT=$(echo "$METRICS" | grep 'kcp_keb_v2_provisioning_duration_minutes_count{plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c"}' | awk '{print $2}')
          PROVISIONING_COUNT=${PROVISIONING_COUNT:-0}
          if [ "$PROVISIONING_COUNT" -eq 0 ]; then
            AVG_PROVISIONING_DURATION=0
          else
            AVG_PROVISIONING_DURATION=$(awk "BEGIN {printf \"%.2f\", ($PROVISIONING_DURATION / $PROVISIONING_COUNT)}")
          fi
          echo "Average duration of provisioning requests: $AVG_PROVISIONING_DURATION minutes" >> $GITHUB_STEP_SUMMARY
          
          scripts/generate_charts.sh
          
          if [[ "$SUCCESS_RATE" != "100.00" ]] && [[ "${{ inputs.test-duration-minutes }}" == "0" ]]; then
            echo "Error: SUCCESS_RATE is $SUCCESS_RATE, expected 100.00"
            exit 1
          fi

      - name: Analyze metrics for leaks
        if: ${{ inputs.post-test-monitoring-minutes > 0 }}
        run: |
          export MEMORY_GROWTH_THRESHOLD_PERCENT=${{ inputs.memory-growth-threshold-percent }}
          export GOROUTINE_INCREASE_THRESHOLD=${{ inputs.goroutine-increase-threshold }}
          export FD_INCREASE_THRESHOLD=${{ inputs.fd-increase-threshold }}
          export DB_CONN_INCREASE_THRESHOLD=${{ inputs.db-conn-increase-threshold }}
          bash scripts/testing/compare_performance_metrics.sh

      - name: Stop metrics collector
        if: always()
        run: |
          if [ -f /tmp/metrics_pid ]; then
            kill $(cat /tmp/metrics_pid) 2>/dev/null || true
          fi

      - name: Upload metrics data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: metrics-provisioning-test
          path: /tmp/keb_metrics.jsonl

  run-concurrent-update-test:
    runs-on: ubuntu-latest
    needs: prepare-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Prepare K3s cluster and docker registry
        run: "./scripts/testing/k3s-setup.sh ${{ needs.prepare-tests.outputs.version }} --wait"

      - name: Prepare values.yaml
        run: |
          yq e ".provisioning.maxStepProcessingTime = \"10s\"" -i resources/keb/values.yaml
          yq e ".provisioning.workersAmount = 100" -i resources/keb/values.yaml
          yq e ".update.maxStepProcessingTime = \"${{ inputs.update-max-step-processing-time }}\"" -i resources/keb/values.yaml
          yq e ".update.workersAmount = ${{ inputs.update-workers-amount }}" -i resources/keb/values.yaml

      - name: Install KEB chart
        run: |
          if [ "${{ inputs.release }}" == "true" ]; then
            make install VERSION="1.25.18"
          else
            make install VERSION="1.25.18"
          fi

      - name: Populate database
        run: |
          DB_NAME=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-db-name}" | base64 -d)
          DB_USER=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-username}" | base64 -d)
          DB_PASS=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-password}" | base64 -d)

          kubectl port-forward -n kcp-system deployment/postgres 5432:5432 &
          PORT_FORWARD_PID=$!
          echo $PORT_FORWARD_PID
          sleep 5

          PGPASSWORD=$DB_PASS psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -f resources/installation/migrations/populate_performance_tests_database.up.sql

          kill $PORT_FORWARD_PID
          
      - name: Start metrics collector
        run: |
          nohup bash scripts/monitor_metrics.sh > /dev/null 2>&1 &
          echo $! > /tmp/metrics_pid

      - name: Baseline monitoring period
        if: ${{ inputs.baseline-monitoring-minutes > 0 }}
        run: |
          echo "Collecting baseline metrics for ${{ inputs.baseline-monitoring-minutes }} minutes..."
          sleep $((${{ inputs.baseline-monitoring-minutes }} * 60))
          echo "Baseline monitoring completed"

      - name: Provision instances
        run: |
          for i in $(seq 1 ${{ inputs.instances-number }}); do
            uid=$(uuidgen)
            curl --request PUT \
              --url http://localhost:30080/oauth/v2/service_instances/$uid \
              --header "Content-Type: application/json" \
              --header "X-Broker-API-Version: 2.16" \
              --data "{\"service_id\":\"47c9dcbf-ff30-448e-ab36-d3bad66ba281\",\"plan_id\":\"4deee563-e5ec-4731-b9b1-53b42d855f0c\",\"context\":{\"globalaccount_id\":\"2f5011af-2fd3-44ba-ac60-eeb1148c2995\",\"subaccount_id\":\"8b9a0db4-9aef-4da2-a856-61a4420b66fd\",\"user_id\":\"user@email.com\"},\"parameters\":{\"name\":\"azure-cluster\",\"region\":\"northeurope\"}}"
          done

          TOTAL_COUNT=$(curl --request GET \
            --url http://localhost:30080/runtimes?plan=azure \
            --header 'Content-Type: application/json' \
            --header 'X-Broker-API-Version: 2.16' | jq .totalCount)

          if [ "$TOTAL_COUNT" -eq "${{ inputs.instances-number }}" ]; then
            echo "Assertion passed: totalCount is $TOTAL_COUNT"
          else
            echo "Assertion failed: totalCount is not ${{ inputs.instances-number }}. Actual value: $TOTAL_COUNT"
            exit 1
          fi

      - name: Simulate KIM
        timeout-minutes: 60
        env:
          KIM_DELAY_SECONDS: 0
        run: |
          scripts/simulate_kim.sh
          
          RESPONSE_JSON=$(curl --request GET \
            --url "http://localhost:30080/runtimes?plan=azure&state=succeeded" \
            --header 'Content-Type: application/json' \
            --header 'X-Broker-API-Version: 2.16')
          SUCCEEDED_TOTAL_COUNT=$(echo "$RESPONSE_JSON" | jq .totalCount)

          if [ "$SUCCEEDED_TOTAL_COUNT" -eq "${{ inputs.instances-number }}" ]; then
            echo "Assertion passed: totalCount is $SUCCEEDED_TOTAL_COUNT"
          else
            echo "Assertion failed: totalCount is not ${{ inputs.instances-number }}. Actual value: $SUCCEEDED_TOTAL_COUNT"
            exit 1
          fi
        
      - name: Update instances
        timeout-minutes: 60
        run: |
          PAGE=1
          
          while true; do
            RESPONSE=$(curl --request GET \
              --url "http://localhost:30080/runtimes?plan=azure&page=$PAGE" \
              --header 'Content-Type: application/json' \
              --header 'X-Broker-API-Version: 2.16')
          
            COUNT=$(echo "$RESPONSE" | jq '.count')
            if [ "$COUNT" -eq 0 ]; then
              break
            fi
          
            echo "$RESPONSE" | jq -r '.data[].instanceID' | while read -r INSTANCE_ID; do
              curl --request PATCH \
                --url "http://localhost:30080/oauth/v2/service_instances/$INSTANCE_ID?accepts_incomplete=true" \
                --header "Content-Type: application/json" \
                --header "X-Broker-API-Version: 2.16" \
                --data '{"service_id":"47c9dcbf-ff30-448e-ab36-d3bad66ba281","plan_id":"4deee563-e5ec-4731-b9b1-53b42d855f0c","context":{"globalaccount_id":"2f5011af-2fd3-44ba-ac60-eeb1148c2995","subaccount_id":"8b9a0db4-9aef-4da2-a856-61a4420b66fd","user_id":"user@email.com"},"parameters":{"autoScalerMax":15}}'
            done
          
            PAGE=$((PAGE + 1))
          done
          
          while true; do
            UPDATED_COUNT=$(curl --request GET \
              --url "http://localhost:30080/runtimes?plan=azure&state=succeeded,failed" \
              --header 'Content-Type: application/json' \
              --header 'X-Broker-API-Version: 2.16' | jq .totalCount)
          
            if [ "$UPDATED_COUNT" -eq "${{ inputs.instances-number }}" ]; then
              echo "All instances are updated. Done."
              break
            fi
          
            sleep 10
          done
        
      - name: Post-test monitoring period
        if: ${{ inputs.post-test-monitoring-minutes > 0 }}
        run: |
          echo "Post-test monitoring for ${{ inputs.post-test-monitoring-minutes }} minutes..."
          sleep $((${{ inputs.post-test-monitoring-minutes }} * 60))
          echo "Post-test monitoring completed"

      - name: Fetch metrics
        run: |
          sleep 15
          
          METRICS=$(curl -s http://localhost:30080/metrics)
          SUCCEEDED_TOTAL=$(echo "$METRICS" | grep 'kcp_keb_v2_operation_result.*plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c".*state="succeeded".*type="update"' | wc -l | xargs)
          SUCCEEDED_TOTAL=${SUCCEEDED_TOTAL:-0}
          FAILED_TOTAL=$(echo "$METRICS" | grep 'kcp_keb_v2_operation_result.*plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c".*state="failed".*type="update"' | wc -l | xargs)
          FAILED_TOTAL=${FAILED_TOTAL:-0}
          TOTAL=$(echo "$SUCCEEDED_TOTAL + $FAILED_TOTAL" | bc)
          if [ "$TOTAL" -eq 0 ]; then
            SUCCESS_RATE=0
          else
            SUCCESS_RATE=$(awk "BEGIN {printf \"%.2f\", ($SUCCEEDED_TOTAL / $TOTAL) * 100}")
          fi
          echo "Success rate of update requests: $SUCCESS_RATE%" >> $GITHUB_STEP_SUMMARY
          
          scripts/generate_charts.sh
          
          if [[ "$SUCCESS_RATE" != "100.00" ]]; then
            echo "Error: SUCCESS_RATE is $SUCCESS_RATE, expected 100.00"
            exit 1
          fi

      - name: Analyze metrics for leaks
        if: ${{ inputs.post-test-monitoring-minutes > 0 }}
        run: |
          export MEMORY_GROWTH_THRESHOLD_PERCENT=${{ inputs.memory-growth-threshold-percent }}
          export GOROUTINE_INCREASE_THRESHOLD=${{ inputs.goroutine-increase-threshold }}
          export FD_INCREASE_THRESHOLD=${{ inputs.fd-increase-threshold }}
          export DB_CONN_INCREASE_THRESHOLD=${{ inputs.db-conn-increase-threshold }}
          bash scripts/testing/compare_performance_metrics.sh

      - name: Stop metrics collector
        if: always()
        run: |
          if [ -f /tmp/metrics_pid ]; then
            kill $(cat /tmp/metrics_pid) 2>/dev/null || true
          fi

      - name: Upload metrics data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: metrics-update-test
          path: /tmp/keb_metrics.jsonl