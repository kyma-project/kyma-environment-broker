name: Run performance tests (reusable)

on:
  workflow_call:
    inputs:
      release:
        description: 'Determines if the workflow is called from release'
        default: "true"
        type: string
      version:
        description: 'Release version'
        default: "0.0.0.0"
        type: string
      instances-number:
        description: number of instances to be provisioned
        default: 100
        type: number
      updates-number:
        description: number of updates on a single instance
        default: 300
        type: number
      kim-delay-seconds:
        description: time to wait before transitioning the runtime CR to the Ready state
        default: 0
        type: number
      provisioning-max-step-processing-time:
        description: max time to process a step in provisioning queue
        default: 30s
        type: string
      provisioning-workers-amount:
        description: amount of workers in provisioning queue
        default: 25
        type: number
      update-max-step-processing-time:
        description: max time to process a step in update queue
        default: 30s
        type: string
      update-workers-amount:
        description: amount of workers in update queue
        default: 25
        type: number
      deprovisioning-max-step-processing-time:
        description: max time to process a step in deprovisioning queue
        default: 30s
        type: string
      deprovisioning-workers-amount:
        description: amount of workers in deprovisioning queue
        default: 25
        type: number
      baseline-monitoring-minutes:
        description: 'Duration of baseline monitoring before tests (minutes)'
        default: 0
        type: number
      post-test-monitoring-minutes:
        description: 'Duration of post-test monitoring after tests (minutes)'
        default: 0
        type: number
      test-duration-minutes:
        description: 'Duration for each test to run (minutes, 0 means run until completion)'
        default: 0
        type: number

jobs:
  prepare-tests:
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.get-version.outputs.k3s_version }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - id: get-version
        name: Get K3s version
        run: |
          VERSION=($(./scripts/testing/get-latest-k3s-releases.sh 1 | jq -r))
          echo "k3s_version=${VERSION}" >> "${GITHUB_OUTPUT}"
      - name: Wait for images to be ready
        uses: wechuli/allcheckspassed@f423b273f5fdf73582e41f8f6f0f204d69c27379
        if: ${{ inputs.release == 'false' }}
        with:
          delay: '1'
          retries: '15'
          polling_interval: '1'
          checks_include: 'kyma-environment-broker-image / Build image, environments-cleanup-image / Build image, deprovision-retrigger-image / Build image, expirator-image / Build image, runtime-reconciler-image / Build image, subaccount-cleanup-image / Build image, subaccount-sync-image / Build image, globalaccounts-image / Build image, schema-migrator-image / Build image, service-binding-cleanup-image / Build image'
          verbose: true

  run-concurrent-provisioning-test:
    runs-on: ubuntu-latest
    needs: prepare-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Prepare K3s cluster and docker registry
        run: "./scripts/testing/k3s-setup.sh ${{ needs.prepare-tests.outputs.version }} --wait"
        
      - name: Prepare values.yaml
        run: |
          yq e ".provisioning.maxStepProcessingTime = \"${{ inputs.provisioning-max-step-processing-time }}\"" -i resources/keb/values.yaml
          yq e ".provisioning.workersAmount = ${{ inputs.provisioning-workers-amount }}" -i resources/keb/values.yaml

      - name: Install KEB chart
        run: |
          if [ "${{ inputs.release }}" == "true" ]; then
            make install VERSION="1.25.17"
          else
            make install VERSION=PR-${{ inputs.version }}
          fi

      - name: Populate database
        run: |
          DB_NAME=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-db-name}" | base64 -d)
          DB_USER=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-username}" | base64 -d)
          DB_PASS=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-password}" | base64 -d)
          
          kubectl port-forward -n kcp-system deployment/postgres 5432:5432 &
          PORT_FORWARD_PID=$!
          echo $PORT_FORWARD_PID
          sleep 5
          
          PGPASSWORD=$DB_PASS psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -f resources/installation/migrations/populate_performance_tests_database.up.sql
          
          kill $PORT_FORWARD_PID
          
      - name: Start metrics collector
        run: |
          nohup bash scripts/monitor_metrics.sh > /dev/null 2>&1 &
          echo $! > /tmp/metrics_pid

      - name: Baseline monitoring period
        if: ${{ inputs.baseline-monitoring-minutes > 0 }}
        run: |
          echo "Collecting baseline metrics for ${{ inputs.baseline-monitoring-minutes }} minutes..."
          sleep $((${{ inputs.baseline-monitoring-minutes }} * 60))
          echo "Baseline monitoring completed"

      - name: Provision instances
        run: |
          START_TIME=$(date +%s)
          TEST_DURATION_SECONDS=$((${{ inputs.test-duration-minutes }} * 60))
          
          if [ "$TEST_DURATION_SECONDS" -gt 0 ]; then
            echo "Running provisioning test for ${{ inputs.test-duration-minutes }} minutes..."
            
            while true; do
              ELAPSED=$(($(date +%s) - START_TIME))
              if [ $ELAPSED -ge $TEST_DURATION_SECONDS ]; then
                echo "Test duration reached, stopping provisioning requests"
                break
              fi
              
              for i in $(seq 1 ${{ inputs.instances-number }}); do
                uid=$(uuidgen)
                curl --request PUT \
                  --url http://localhost:30080/oauth/v2/service_instances/$uid \
                  --header "Content-Type: application/json" \
                  --header "X-Broker-API-Version: 2.16" \
                  --data "{\"service_id\":\"47c9dcbf-ff30-448e-ab36-d3bad66ba281\",\"plan_id\":\"4deee563-e5ec-4731-b9b1-53b42d855f0c\",\"context\":{\"globalaccount_id\":\"2f5011af-2fd3-44ba-ac60-eeb1148c2995\",\"subaccount_id\":\"8b9a0db4-9aef-4da2-a856-61a4420b66fd\",\"user_id\":\"user@email.com\"},\"parameters\":{\"name\":\"azure-cluster\",\"region\":\"northeurope\"}}"
              done
              
              echo "Provisioned batch of ${{ inputs.instances-number }} instances, elapsed: ${ELAPSED}s"
              sleep 10
            done
          else
            echo "Running provisioning test once..."
            for i in $(seq 1 ${{ inputs.instances-number }}); do
              uid=$(uuidgen)
              curl --request PUT \
                --url http://localhost:30080/oauth/v2/service_instances/$uid \
                --header "Content-Type: application/json" \
                --header "X-Broker-API-Version: 2.16" \
                --data "{\"service_id\":\"47c9dcbf-ff30-448e-ab36-d3bad66ba281\",\"plan_id\":\"4deee563-e5ec-4731-b9b1-53b42d855f0c\",\"context\":{\"globalaccount_id\":\"2f5011af-2fd3-44ba-ac60-eeb1148c2995\",\"subaccount_id\":\"8b9a0db4-9aef-4da2-a856-61a4420b66fd\",\"user_id\":\"user@email.com\"},\"parameters\":{\"name\":\"azure-cluster\",\"region\":\"northeurope\"}}"
            done
          fi
          
          TOTAL_COUNT=$(curl --request GET \
            --url http://localhost:30080/runtimes?plan=azure \
            --header 'Content-Type: application/json' \
            --header 'X-Broker-API-Version: 2.16' | jq .totalCount)

          echo "Total instances created: $TOTAL_COUNT"
      
      - name: Simulate KIM
        timeout-minutes: 60
        env:
          KIM_DELAY_SECONDS: ${{ inputs.kim-delay-seconds }}
        run: scripts/simulate_kim.sh
        
      - name: Post-test monitoring period
        if: ${{ inputs.post-test-monitoring-minutes > 0 }}
        run: |
          echo "Post-test monitoring for ${{ inputs.post-test-monitoring-minutes }} minutes..."
          sleep $((${{ inputs.post-test-monitoring-minutes }} * 60))
          echo "Post-test monitoring completed"
          
      - name: Fetch metrics
        run: |          
          METRICS=$(curl -s http://localhost:30080/metrics)
          
          SUCCEEDED_TOTAL=$(echo "$METRICS" | grep 'kcp_keb_v2_operations_provisioning_succeeded_total{plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c"}' | awk '{print $2}')
          SUCCEEDED_TOTAL=${SUCCEEDED_TOTAL:-0}
          FAILED_TOTAL=$(echo "$METRICS" | grep 'kcp_keb_v2_operations_provisioning_failed_total{plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c"}' | awk '{print $2}')
          FAILED_TOTAL=${FAILED_TOTAL:-0}
          TOTAL=$(echo "$SUCCEEDED_TOTAL + $FAILED_TOTAL" | bc)
          if [ "$TOTAL" -eq 0 ]; then
            SUCCESS_RATE=0
          else
            SUCCESS_RATE=$(awk "BEGIN {printf \"%.2f\", ($SUCCEEDED_TOTAL / $TOTAL) * 100}")
          fi
          echo "Success rate of provisioning requests: $SUCCESS_RATE%" >> $GITHUB_STEP_SUMMARY
          
          PROVISIONING_DURATION=$(echo "$METRICS" | grep 'kcp_keb_v2_provisioning_duration_minutes_sum{plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c"}' | awk '{print $2}')
          PROVISIONING_DURATION=${PROVISIONING_DURATION:-0}
          PROVISIONING_COUNT=$(echo "$METRICS" | grep 'kcp_keb_v2_provisioning_duration_minutes_count{plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c"}' | awk '{print $2}')
          PROVISIONING_COUNT=${PROVISIONING_COUNT:-0}
          if [ "$PROVISIONING_COUNT" -eq 0 ]; then
            AVG_PROVISIONING_DURATION=0
          else
            AVG_PROVISIONING_DURATION=$(awk "BEGIN {printf \"%.2f\", ($PROVISIONING_DURATION / $PROVISIONING_COUNT)}")
          fi
          echo "Average duration of provisioning requests: $AVG_PROVISIONING_DURATION minutes" >> $GITHUB_STEP_SUMMARY
          
          scripts/generate_charts.sh
          
          if [[ "$SUCCESS_RATE" != "100.00" ]] && [[ "${{ inputs.test-duration-minutes }}" == "0" ]]; then
            echo "Error: SUCCESS_RATE is $SUCCESS_RATE, expected 100.00"
            exit 1
          fi

      - name: Analyze metrics for leaks
        if: ${{ inputs.post-test-monitoring-minutes > 0 }}
        run: |
          bash scripts/testing/compare_performance_metrics.sh

      - name: Stop metrics collector
        if: always()
        run: |
          if [ -f /tmp/metrics_pid ]; then
            kill $(cat /tmp/metrics_pid) 2>/dev/null || true
          fi

      - name: Upload metrics data
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: metrics-provisioning-test
          path: /tmp/keb_metrics.jsonl


    runs-on: ubuntu-latest
    needs: prepare-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Prepare K3s cluster and docker registry
        run: "./scripts/testing/k3s-setup.sh ${{ needs.prepare-tests.outputs.version }} --wait"

      - name: Prepare values.yaml
        run: |
          yq e ".update.maxStepProcessingTime = \"${{ inputs.update-max-step-processing-time }}\"" -i resources/keb/values.yaml
          yq e ".update.workersAmount = ${{ inputs.update-workers-amount }}" -i resources/keb/values.yaml

      - name: Install KEB chart
        run: |
          if [ "${{ inputs.release }}" == "true" ]; then
            make install VERSION=${{ inputs.version }}
          else
            make install VERSION=PR-${{ inputs.version }}
          fi

      - name: Populate database
        run: |
          DB_NAME=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-db-name}" | base64 -d)
          DB_USER=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-username}" | base64 -d)
          DB_PASS=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-password}" | base64 -d)

          kubectl port-forward -n kcp-system deployment/postgres 5432:5432 &
          PORT_FORWARD_PID=$!
          echo $PORT_FORWARD_PID
          sleep 5

          PGPASSWORD=$DB_PASS psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -f resources/installation/migrations/populate_performance_tests_database.up.sql

          kill $PORT_FORWARD_PID
          
      - name: Start metrics collector
        run: |
          nohup bash scripts/monitor_metrics.sh > /dev/null 2>&1 &
          echo $! > /tmp/metrics_pid

      - name: Provision the instance
        run: |
          curl --request PUT \
            --url http://localhost:30080/oauth/v2/service_instances/azure-cluster \
            --header "Content-Type: application/json" \
            --header "X-Broker-API-Version: 2.16" \
            --data "{\"service_id\":\"47c9dcbf-ff30-448e-ab36-d3bad66ba281\",\"plan_id\":\"4deee563-e5ec-4731-b9b1-53b42d855f0c\",\"context\":{\"globalaccount_id\":\"2f5011af-2fd3-44ba-ac60-eeb1148c2995\",\"subaccount_id\":\"8b9a0db4-9aef-4da2-a856-61a4420b66fd\",\"user_id\":\"user@email.com\"},\"parameters\":{\"name\":\"azure-cluster\",\"region\":\"northeurope\"}}"

      - name: Simulate KIM
        timeout-minutes: 60
        env:
          KIM_DELAY_SECONDS: 0
        run: |
          scripts/simulate_kim.sh

          INSTANCE_JSON=$(curl --request GET \
            --url "http://localhost:30080/runtimes?instance_id=azure-cluster" \
            --header 'Content-Type: application/json' \
            --header 'X-Broker-API-Version: 2.16')
          INSTANCE_STATE=$(echo "$INSTANCE_JSON" | jq '.data[0].status.state')

          if [ "$INSTANCE_STATE" = '"succeeded"' ]; then
            echo "Assertion passed: state is $INSTANCE_STATE"
          else
            echo "Assertion failed: state is not 'succeeded'. Actual value: $INSTANCE_STATE"
            exit 1
          fi

      - name: Update the instance
        timeout-minutes: 60
        run: |
          max=5
          for i in $(seq 1 ${{ inputs.updates-number }}); do
            curl --request PATCH \
              --url "http://localhost:30080/oauth/v2/service_instances/azure-cluster?accepts_incomplete=true" \
              --header "Content-Type: application/json" \
              --header "X-Broker-API-Version: 2.16" \
              --data "{\"service_id\":\"47c9dcbf-ff30-448e-ab36-d3bad66ba281\",\"plan_id\":\"4deee563-e5ec-4731-b9b1-53b42d855f0c\",\"context\":{\"globalaccount_id\":\"2f5011af-2fd3-44ba-ac60-eeb1148c2995\",\"subaccount_id\":\"8b9a0db4-9aef-4da2-a856-61a4420b66fd\",\"user_id\":\"user@email.com\"},\"parameters\":{\"autoScalerMax\":$max}}"
    
            max=$((max + 1))
            if [ "$max" -gt 100 ]; then
              max=5
            fi
          done
          
          while true; do
            INSTANCE_STATE=$(curl --request GET \
              --url "http://localhost:30080/runtimes?instance_id=azure-cluster" \
              --header 'Content-Type: application/json' \
              --header 'X-Broker-API-Version: 2.16' | jq '.data[0].status.state')

            if [ "$INSTANCE_STATE" = '"succeeded"' ]; then
              echo "Instance is updated. Done."
              break
            fi

            sleep 10
          done

      - name: Fetch metrics
        run: |
          sleep 15

          METRICS=$(curl -s http://localhost:30080/metrics)
          SUCCEEDED_TOTAL=$(echo "$METRICS" | grep 'kcp_keb_v2_operation_result.*plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c".*state="succeeded".*type="update"' | wc -l | xargs)
          SUCCEEDED_TOTAL=${SUCCEEDED_TOTAL:-0}
          FAILED_TOTAL=$(echo "$METRICS" | grep 'kcp_keb_v2_operation_result.*plan_id="4deee563-e5ec-4731-b9b1-53b42d855f0c".*state="failed".*type="update"' | wc -l | xargs)
          FAILED_TOTAL=${FAILED_TOTAL:-0}
          TOTAL=$(echo "$SUCCEEDED_TOTAL + $FAILED_TOTAL" | bc)
          if [ "$TOTAL" -eq 0 ]; then
            SUCCESS_RATE=0
          else
            SUCCESS_RATE=$(awk "BEGIN {printf \"%.2f\", ($SUCCEEDED_TOTAL / $TOTAL) * 100}")
          fi
          echo "Success rate of update requests: $SUCCESS_RATE%" >> $GITHUB_STEP_SUMMARY

          scripts/generate_charts.sh
          
          if [[ "$SUCCESS_RATE" != "100.00" ]]; then
            echo "Error: SUCCESS_RATE is $SUCCESS_RATE, expected 100.00"
            exit 1
          fi
          
    runs-on: ubuntu-latest
    needs: prepare-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Prepare K3s cluster and docker registry
        run: "./scripts/testing/k3s-setup.sh ${{ needs.prepare-tests.outputs.version }} --wait"

      - name: Install KEB chart
        run: |
          if [ "${{ inputs.release }}" == "true" ]; then
            make install VERSION=${{ inputs.version }}
          else
            make install VERSION=PR-${{ inputs.version }}
          fi
          
      - name: Start metrics collector
        run: |
          nohup bash scripts/monitor_metrics.sh > /dev/null 2>&1 &
          echo $! > /tmp/metrics_pid

      - name: Fetch runtimes using GET endpoint
        run: |
          kubectl port-forward -n kcp-system deployment/postgres 5432:5432 &
          sleep 5
          
          DB_NAME=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-db-name}" | base64 -d)
          DB_USER=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-username}" | base64 -d)
          DB_PASS=$(kubectl get secret kcp-postgresql -n kcp-system -o jsonpath="{.data.postgresql-broker-password}" | base64 -d)
          
          PGPASSWORD=$DB_PASS psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -f resources/installation/migrations/populate_performance_tests_database.up.sql
          
          SUCCESS_COUNT=0
          for i in {1..100}; do
            STATUS_CODE=$(curl --write-out "%{http_code}" --silent --output /dev/null \
              --request GET \
              --url "http://localhost:30080/runtimes" \
              --header 'Content-Type: application/json' \
              --header 'X-Broker-API-Version: 2.16')
            if [[ "$STATUS_CODE" == "200" ]]; then
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
            fi
          done
          SUCCESS_RATE=$((SUCCESS_COUNT * 100 / 100))
          echo "Success rate of runtimes requests: $SUCCESS_RATE%" >> $GITHUB_STEP_SUMMARY

          echo "<div align=\"center\">" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "| Number of Instances | Average Time per Page | Maximum Time per Page |" >> $GITHUB_STEP_SUMMARY
          echo "| :---: | :---: | :---: |" >> $GITHUB_STEP_SUMMARY

          fetch_and_measure() {
            local num_instances=$1
            local pages=$2

            TOTAL_TIME=0
            MAX_TIME=0

            for PAGE in $(seq 1 $pages); do
              START=$(date +%s%3N)
              curl --silent --request GET \
                --url "http://localhost:30080/runtimes?page=$PAGE" \
                --header 'Content-Type: application/json' \
                --header 'X-Broker-API-Version: 2.16' > /dev/null
              END=$(date +%s%3N)
              ELAPSED=$((END - START))
              TOTAL_TIME=$((TOTAL_TIME + ELAPSED))
              if (( ELAPSED > MAX_TIME )); then
                MAX_TIME=$ELAPSED
              fi
            done
            AVG_TIME=$((TOTAL_TIME / pages))

            echo "| $num_instances | $AVG_TIME ms | $MAX_TIME ms |" >> $GITHUB_STEP_SUMMARY
          }

          # 1k
          fetch_and_measure 1000 10

          # 10k
          for i in {1..9}; do
            PGPASSWORD=$DB_PASS psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -f resources/installation/migrations/populate_performance_tests_database.up.sql
          done
          fetch_and_measure 10000 100

          # 100k
          for i in {1..90}; do
            PGPASSWORD=$DB_PASS psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -f resources/installation/migrations/populate_performance_tests_database.up.sql
          done
          fetch_and_measure 100000 100

          echo "</div>" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          
          if [[ "$SUCCESS_RATE" != "100" ]]; then
            echo "Error: SUCCESS_RATE is $SUCCESS_RATE, expected 100"
            exit 1
          fi

      - name: Fetch metrics
        run: scripts/generate_charts.sh